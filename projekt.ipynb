{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (250, 3, 32, 32) containing float32\n",
      " - an array of size (250, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "train_batch_size = 100\n",
    "validation_batch_size = 250\n",
    "\n",
    "\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}), \n",
    "    #(Flatten, [], {'which_sources': 'features'}),\n",
    "    #(Flatten, [], {'which_sources': 'targets'}),\n",
    "    #(Mapping, [lambda batch: (b.T for b in batch)], {}) \n",
    "    )\n",
    "\n",
    "cifar_train = CIFAR10((\"train\",), subset=slice(None,45000))\n",
    "cifar_train_stream = DataStream.default_stream(\n",
    "    cifar_train,\n",
    "    iteration_scheme=ShuffledScheme(cifar_train.num_examples, train_batch_size))\n",
    "\n",
    "cifar_validation = CIFAR10((\"train\",), subset=slice(45000, None))\n",
    "cifar_validation_stream = DataStream.default_stream(\n",
    "    cifar_validation, iteration_scheme=SequentialScheme(cifar_validation.num_examples, validation_batch_size))\n",
    "\n",
    "cifar_test = CIFAR10((\"test\",))\n",
    "cifar_test_stream = DataStream.default_stream(\n",
    "    cifar_test, iteration_scheme=SequentialScheme(cifar_test.num_examples, validation_batch_size))\n",
    "\n",
    "print \"The streams return batches containing %s\" % (cifar_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "\n",
    "cifar_labels = [\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.657853 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create Theano variables for input and target minibatch\n",
    "input_var = T.tensor4('X')\n",
    "target_var = T.ivector('y')\n",
    "\n",
    "# create a small convolutional neural network\n",
    "from lasagne.nonlinearities import leaky_rectify, softmax\n",
    "network = lasagne.layers.InputLayer((None, 3, 32, 32), input_var)\n",
    "network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "                                     nonlinearity=leaky_rectify, pad='same')\n",
    "network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "                                     nonlinearity=leaky_rectify, pad='same')\n",
    "network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "                                     nonlinearity=leaky_rectify, pad='same')\n",
    "# network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "#                                      nonlinearity=leaky_rectify, pad='same')\n",
    "# network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "#                                      nonlinearity=leaky_rectify, pad='same')\n",
    "# network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "#                                      nonlinearity=leaky_rectify, pad='same')\n",
    "#network = lasagne.layers.Conv2DLayer(network, 32, (5, 5),\n",
    "#                                     nonlinearity=leaky_rectify)\n",
    "network = lasagne.layers.Pool2DLayer(network, (2, 2), stride=2, mode='max')\n",
    "network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "                                     nonlinearity=leaky_rectify, pad='same')\n",
    "network = lasagne.layers.Pool2DLayer(network, (2, 2), stride=2, mode='max')\n",
    "network = lasagne.layers.Conv2DLayer(network, 128, (5, 5),\n",
    "                                     nonlinearity=leaky_rectify, pad='same')\n",
    "network = lasagne.layers.Conv2DLayer(network, 64, (5, 5),\n",
    "                                     nonlinearity=leaky_rectify, pad='same')\n",
    "network = lasagne.layers.Pool2DLayer(network, (8, 8), stride=8, mode='max')\n",
    "#network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, 0.5),\n",
    "#                                    128, nonlinearity=leaky_rectify,\n",
    "#                                    W=lasagne.init.Orthogonal())\n",
    "network = lasagne.layers.DenseLayer(lasagne.layers.dropout(network, 0.5),\n",
    "                                    10, nonlinearity=softmax)\n",
    "\n",
    "# create loss function\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean() + 1e-4 * lasagne.regularization.regularize_network_params(\n",
    "        network, lasagne.regularization.l2)\n",
    "\n",
    "a0 = np.float32(0.02)\n",
    "tau = np.float32(cifar_train.num_examples)\n",
    "learning_rate = theano.shared(np.array(a0, dtype=config.floatX))\n",
    "t = T.scalar()\n",
    "anneal_learning_rate = theano.function([t], None, updates=[\n",
    "        (learning_rate, a0 * (tau / T.max([t, tau])))])\n",
    "\n",
    "# create parameter update expressions\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=learning_rate,\n",
    "                                            momentum=0.9)\n",
    "#updates = lasagne.updates.rmsprop(loss, params, learning_rate=0.1)\n",
    "# compile training function that updates parameters and returns training loss\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "test_loss = loss.mean() + 1e-4 * lasagne.regularization.regularize_network_params(\n",
    "        network, lasagne.regularization.l2)\n",
    "\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-93e71815f69c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcifar_train_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epoch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i247930/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i247930/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoContext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_err = np.inf\n",
    "best_params = lasagne.layers.get_all_param_values(network)\n",
    "best_params_epoch = 0\n",
    "    \n",
    "num_epochs = 5\n",
    "patience_expansion = 1.5\n",
    "\n",
    "\n",
    "print(\"Starting training...\")\n",
    "epoch = 0\n",
    "t = 0\n",
    "while epoch < num_epochs:\n",
    "    epoch += 1\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for input_batch, target_batch in cifar_train_stream.get_epoch_iterator():\n",
    "        train_err += train_fn(input_batch, target_batch.ravel())\n",
    "        train_batches += 1\n",
    "        t += train_batch_size\n",
    "        anneal_learning_rate(t)\n",
    "        \n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for input_batch, target_batch in cifar_validation_stream.get_epoch_iterator():\n",
    "        err, acc = val_fn(input_batch, target_batch.ravel())\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "\n",
    "    print(\"Learning rate: {:.6f}\".format(float(learning_rate.get_value())))\n",
    "    \n",
    "    # patience expansion\n",
    "    if val_err < best_val_err:\n",
    "        planned_num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
    "        if planned_num_epochs > num_epochs:\n",
    "            print \"After epoch %d: increased planned number of epochs to %d\" % (epoch, planned_num_epochs)\n",
    "        num_epochs = planned_num_epochs\n",
    "        best_val_err = val_err\n",
    "        best_params = lasagne.layers.get_all_param_values(network)\n",
    "        best_params_epoch = epoch\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test loss:\t\t\t2.503963\n",
      "  test accuracy:\t\t8.34 %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mismatch: got 12 values to set 20 parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-b616fd584a3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_all_param_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtest_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i247930/.local/lib/python2.7/site-packages/lasagne/layers/helper.pyc\u001b[0m in \u001b[0;36mset_all_param_values\u001b[1;34m(layer, values, **tags)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         raise ValueError(\"mismatch: got %d values to set %d parameters\" %\n\u001b[1;32m--> 446\u001b[1;33m                          (len(values), len(params)))\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: mismatch: got 12 values to set 20 parameters"
     ]
    }
   ],
   "source": [
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for input_batch, target_batch in cifar_test_stream.get_epoch_iterator():\n",
    "    err, acc = val_fn(input_batch, target_batch.ravel())\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "\n",
    "lasagne.layers.set_all_param_values(network, best_params)\n",
    "\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for input_batch, target_batch in cifar_test_stream.get_epoch_iterator():\n",
    "    err, acc = val_fn(input_batch, target_batch.ravel())\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results (using best_params from epoch {}:\".format(best_params_epoch))\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
